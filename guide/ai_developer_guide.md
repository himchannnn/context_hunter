# Context Hunter - AI 엔지니어 가이드

## 1. 개요
**Context Hunter**의 AI 모듈(`backend/ai.py`)은 단순한 챗봇이 아닌, **규칙 기반의 콘텐츠 생성기(Procedural Content Generation via LLM)**입니다. OpenAI API 인터페이스를 활용하여 로컬 구동되는 `Gemma-2` (또는 Llama-3) 모델을 제어합니다.

### 핵심 역할
1.  **동적 문제 생성**: 사전에 없는 문장을 실시간으로 창작하고 암호화된 고난이도 문장으로 변환.
2.  **의미 기반 채점**: 단순 키워드 매칭이 아닌, 사용자의 문장이 원문의 의도를 내포하는지 '문해력' 관점에서 평가.

---

## 2. 프롬프트 엔지니어링 구조

### A. 문제 생성 (`generate_question`)
가장 복잡한 프롬프트가 사용됩니다. 품질 보장을 위해 **Chain of Thought(생각의 사슬)** 기법을 강제합니다.

-   **Discovery Mode (50%)**: AI가 스스로 난이도에 맞는 단어를 선정하도록 유도합니다. "패턴 피로도(Pattern Fatigue)"를 줄이기 위함입니다.
-   **Strict Constraints**:
    -   *Dictionary Check*: "표준국어대사전에 있는 단어인가?"를 먼저 자문하게 함으로써 없는 단어(Hallucination) 생성을 억제합니다.
    -   *No Translationese*: 번역투 문장을 금지하고 자연스러운 한국어 어미(~했다, ~인가?) 사용을 강제합니다.
    -   *JSON Mode*: 출력 포맷을 엄격한 JSON으로 제한하여 파싱 에러를 방지합니다.

### B. 유사도 채점 (`check_similarity`)
사용자 답안을 평가하는 '엄격한 선생님' 페르소나를 부여합니다.

-   **Scoring Logic**:
    -   **Context Matters**: 단순 번역이 아니라, 원문의 '어려운 단어'를 '쉬운 단어'로 잘 풀어서 설명했는지를 봅니다.
    -   **점수 체계**: 0~100점 사이의 정수값을 반환하며, 50점 이상을 정답(`True`)으로 간주합니다.
    -   **할루시네이션 방지**: 코사인 유사도(Embedding) 방식 대신 LLM에게 논리적 판단을 맡겨, "반대말이지만 문장은 비슷한" 경우(정반대 오답)를 걸러냅니다.

---

## 3. 자체 검증 시스템 (Self-Correction Loop)

AI가 생성한 결과물은 100% 신뢰할 수 없으므로, **`_verify_and_fix_question`** 함수를 통해 2차 검증을 수행합니다.

1.  **생성**: 1차 프롬프트로 결과물 생성.
2.  **검증**: 생성된 JSON을 다시 입력으로 넣고, "Senior Editor" 페르소나를 가진 다른 프롬프트 세션이 이를 평가합니다.
    -   *체크리스트*: "문법적으로 완벽한가?", "단어의 정의가 문맥과 일치하는가?", "한자가 포함되어 있진 않은가?"
3.  **수정**: 만약 결함이 발견되면 AI가 스스로 수정한 버전을 반환합니다.

이 과정은 응답 시간(Latency)을 약 1.5~2배 증가시키지만, 콘텐츠 품질을 비약적으로 향상시키는 **Quality Gate** 역할을 합니다.

---

## 4. 모델 설정 및 최적화

-   **모델**: `Gemma-2 (9B)` 또는 `Llama-3 (8B)` 권장. (한국어 성능과 추론 속도의 밸런스)
-   **Temperature**:
    -   문제 생성 시: `0.7` (다양성을 위해 약간의 창의성 허용)
    -   채점/검증 시: `0.1` (일관되고 엄격한 판단을 위해 매우 낮게 설정)
-   **Resource**: `docker-compose` 설정상 GPU 1장을 할당받으며, `OLLAMA_KEEP_ALIVE=0`으로 설정하여 요청 처리 직후 VRAM을 즉시 반환, 서버 자원을 효율적으로 공유합니다.

---

## 5. 발표 및 설명 팁 (Q&A 대비)

**Q. "왜 RAG(검색 증강 생성)를 쓰지 않고 LLM에게 창작을 시켰나?"**
> "RAG는 기존 문서를 검색하는 데 특화되어 있습니다. 우리는 사용자가 매번 '완전히 새로운' 문장을 접하길 원했습니다. 단, 할루시네이션 위험은 'Self-Reflection(자가검증)' 파이프라인을 통해 통제하고 있습니다."

**Q. "채점의 공정성은 어떻게 보장하나?"**
> "기존의 BERT/Cosine 유사도는 '문장 구조'가 비슷하면 점수를 높게 주는 맹점이 있습니다. 하지만 LLM 채점 방식은 의미(Semantics)를 이해합니다. 예를 들어 '그는 사퇴했다'와 '그는 자리에서 물러났다'는 단어가 전혀 달라도 100점(유사함)을 주지만, '그는 사퇴하지 않았다'는 한 글자 차이라도 0점(다름)을 줄 수 있습니다. 이것이 LLM 채점의 핵심 장점입니다."

**Q. "Gemma-2 모델을 선택한 근거는?"**
> "Google의 Gemma-2는 상대적으로 작은 파라미터(9B)로도 한국어 문맥 이해도가 타 모델(Mistral 등) 대비 월등히 높았습니다. 학과 서버의 제한된 GPU 메모리 안에서 최고의 '한국어 문해력 교육' 성능을 내기 위한 최적의 선택이었습니다."
